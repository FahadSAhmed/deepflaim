{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named imblearn.over_sampling",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-471849ff928e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mimblearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mover_sampling\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSMOTE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named imblearn.over_sampling"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.stats import zscore\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "numpy.random.seed(7)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 2] File E:\\Parkinsons Disease PD with Papers/TSurg_Adults_sorted.csv does not exist: 'E:\\\\Parkinsons Disease PD with Papers/TSurg_Adults_sorted.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-4b7537bc1a32>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Importing the Train Data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"E:\\Parkinsons Disease PD with Papers/TSurg_Adults_sorted.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda2/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda2/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda2/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda2/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1122\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1123\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda2/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1851\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1853\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1854\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1855\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: [Errno 2] File E:\\Parkinsons Disease PD with Papers/TSurg_Adults_sorted.csv does not exist: 'E:\\\\Parkinsons Disease PD with Papers/TSurg_Adults_sorted.csv'"
     ]
    }
   ],
   "source": [
    "#Importing the Train Data \n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"E:\\Parkinsons Disease PD with Papers/TSurg_Adults_sorted.csv\")\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3008, 37)\n"
     ]
    }
   ],
   "source": [
    "print(df_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['﻿icustay_id', 'hadm_id', 'subject_id', 'aniongap_Abnorm',\n",
      "       'albumin_Abnorm1', 'bicarbonate_Abnorm1', 'bilirubin_Abnorm1',\n",
      "       'creatinine_Abnorm1', 'chloride_Abnorm1', 'glucose_Abnorm1',\n",
      "       'hematocrit_Abnorm1', 'hemoglobin_Abnorm1', 'lactate_Abnorm1',\n",
      "       'platelet_Abnorm1', 'potassium_Abnorm1', 'ptt_Abnorm1', 'inr_Abnorm1',\n",
      "       'pt_Abnorm1', 'sodium_Abnorm1', 'bun_Abnorm1', 'wbc_Abnorm1', 'DOD_1_0',\n",
      "       'Exp_sepsis', 'Angus_Sepsis', 'APS3_day1', 'LODS_day1',\n",
      "       'Martin_sepsis_day1', 'Oasis_sepsis_day1', 'qSOFA_day1', 'SAPS_day1',\n",
      "       'SAPSII_day1', 'SIRS_day1', 'SOFA_day1', 'los_hospital', 'los_icu',\n",
      "       'gender', 'Ethino_white'],\n",
      "      dtype='object')\n",
      "(3008,)\n",
      "4       0.0\n",
      "5       0.0\n",
      "6       1.0\n",
      "7       0.0\n",
      "8       0.0\n",
      "9       0.0\n",
      "10      0.0\n",
      "11      0.0\n",
      "13      1.0\n",
      "14      0.0\n",
      "15      0.0\n",
      "17      0.0\n",
      "18      0.0\n",
      "19      0.0\n",
      "20      0.0\n",
      "21      0.0\n",
      "22      0.0\n",
      "23      0.0\n",
      "24      0.0\n",
      "25      0.0\n",
      "26      0.0\n",
      "27      0.0\n",
      "28      0.0\n",
      "29      0.0\n",
      "30      0.0\n",
      "31      0.0\n",
      "33      0.0\n",
      "34      0.0\n",
      "35      0.0\n",
      "36      0.0\n",
      "       ... \n",
      "2992    1.0\n",
      "2993    0.0\n",
      "2994    1.0\n",
      "2995    0.0\n",
      "2996    1.0\n",
      "2997    1.0\n",
      "2998    1.0\n",
      "2999    1.0\n",
      "3000    1.0\n",
      "3001    0.0\n",
      "3002    1.0\n",
      "3003    0.0\n",
      "3004    1.0\n",
      "3005    0.0\n",
      "3006    1.0\n",
      "3007    0.0\n",
      "3008    1.0\n",
      "3009    0.0\n",
      "3010    1.0\n",
      "3011    0.0\n",
      "3012    1.0\n",
      "3013    1.0\n",
      "3014    1.0\n",
      "3015    1.0\n",
      "3016    1.0\n",
      "3017    1.0\n",
      "3018    1.0\n",
      "3019    1.0\n",
      "3020    0.0\n",
      "3021    1.0\n",
      "Name: DOD_1_0, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(df_new.columns)\n",
    "Y_df = df_new['DOD_1_0']\n",
    "print(Y_df.shape)\n",
    "print(Y_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3008, 33)\n"
     ]
    }
   ],
   "source": [
    "X_df = df_new.drop(['﻿icustay_id', 'hadm_id', 'subject_id', 'DOD_1_0'], axis=1)\n",
    "print(X_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['aniongap_Abnorm', 'albumin_Abnorm1', 'bicarbonate_Abnorm1',\n",
       "       'bilirubin_Abnorm1', 'creatinine_Abnorm1', 'chloride_Abnorm1',\n",
       "       'glucose_Abnorm1', 'hematocrit_Abnorm1', 'hemoglobin_Abnorm1',\n",
       "       'lactate_Abnorm1', 'platelet_Abnorm1', 'potassium_Abnorm1',\n",
       "       'ptt_Abnorm1', 'inr_Abnorm1', 'pt_Abnorm1', 'sodium_Abnorm1',\n",
       "       'bun_Abnorm1', 'wbc_Abnorm1', 'Exp_sepsis', 'Angus_Sepsis', 'APS3_day1',\n",
       "       'LODS_day1', 'Martin_sepsis_day1', 'Oasis_sepsis_day1', 'qSOFA_day1',\n",
       "       'SAPS_day1', 'SAPSII_day1', 'SIRS_day1', 'SOFA_day1', 'los_hospital',\n",
       "       'los_icu', 'gender', 'Ethino_white'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = numpy.array(X_df)\n",
    "Y = numpy.array(Y_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "340.0\n"
     ]
    }
   ],
   "source": [
    "print(Y.sum())\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(903,)\n",
      "115.0\n",
      "788.0\n"
     ]
    }
   ],
   "source": [
    "print(Y_test.shape)\n",
    "print(Y_test.sum())\n",
    "print(903-Y_test.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FLAIM-Net: A Statistically Rigorous Neural Network Approach to Early "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc ================================== 92.24806201550388\n",
      "Training Acc = 93.82422802850357\n",
      "Sen = 79.13043478260869\n",
      "Spec = 94.16243654822335\n",
      "Testing Acc from TP and TN= 92.24806201550388\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=42)\n",
    "sm = SMOTE(random_state=42)\n",
    "X_train_bal, Y_train_bal = sm.fit_resample(X_train, Y_train)\n",
    "##############10 Fold for each subset of features############\n",
    "n1 =7\n",
    "n2=5\n",
    "Best_Acc=0\n",
    "\n",
    "TP = 0\n",
    "TN = 0\n",
    "FP = 0\n",
    "FN = 0\n",
    "model =  MLPClassifier(solver='adam', hidden_layer_sizes=(n1, n2), random_state=1)\n",
    "#model =  RandomForestClassifier(n_estimators=e, max_depth=d, random_state=0)\n",
    "model.fit(X_train_bal, Y_train_bal)\n",
    "Y_pred = model.predict(X_test)\n",
    "Acc = accuracy_score(Y_test, Y_pred)*100\n",
    "\n",
    "\n",
    "print(\"Acc ==================================\", Acc)\n",
    "\n",
    "k=0\n",
    "while(k< len(Y_pred)):\n",
    "    if Y_pred[k]==Y_test[k]==1:\n",
    "        TP = TP+1\n",
    "    if Y_pred[k]==Y_test[k]==0:\n",
    "        TN = TN+1\n",
    "    k = k+1\n",
    "FP = 788-TN\n",
    "FN = 115-TP\n",
    "Y_pred = model.predict(X_train)\n",
    "Acc = accuracy_score(Y_train, Y_pred)*100\n",
    "print(\"Training Acc =\", Acc)\n",
    "\n",
    "print(\"Sen =\", (TP/115)*100)\n",
    "print(\"Spec =\", (TN/788)*100)\n",
    "print(\"Testing Acc from TP and TN=\", ((TP+TN)/903)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
